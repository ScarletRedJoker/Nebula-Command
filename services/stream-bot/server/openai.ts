// Reference: javascript_openai_ai_integrations blueprint
import OpenAI from "openai";
import pRetry, { AbortError } from "p-retry";
import { getOpenAIConfig, isReplit } from "../src/config/environment";

// Use environment-aware configuration
let openai: OpenAI | null = null;
let isOpenAIEnabled = false;

try {
  const config = getOpenAIConfig();
  openai = new OpenAI({
    baseURL: config.baseURL,
    apiKey: config.apiKey
  });
  isOpenAIEnabled = true;
  const envType = isReplit() ? "Replit" : "Production";
  console.log(`[OpenAI] AI Service initialized with ${envType} credentials`);
  console.log(`[OpenAI]   Base URL: ${config.baseURL}`);
  console.log(`[OpenAI]   Model: ${config.model}`);
} catch (error) {
  console.warn(`[OpenAI] AI features disabled: ${error instanceof Error ? error.message : String(error)}`);
}

export { isOpenAIEnabled };

// Helper function to check if error is rate limit or quota violation
function isRateLimitError(error: any): boolean {
  const errorMsg = error?.message || String(error);
  return (
    errorMsg.includes("429") ||
    errorMsg.includes("RATELIMIT_EXCEEDED") ||
    errorMsg.toLowerCase().includes("quota") ||
    errorMsg.toLowerCase().includes("rate limit")
  );
}

const DEFAULT_PROMPT = `Generate a fun, interesting, and mind-blowing fact about life, the universe, science, history, nature, or weird phenomena. These should be surprising Snapple-style facts that make people say "wow, I didn't know that!" 

Topics to explore: space, animals, physics, human body, ancient civilizations, food science, geography, inventions, music, art, mathematics, weird laws, unusual traditions, or bizarre natural phenomena.

Keep it under 200 characters so it fits in a chat message. Just return the fact itself, no quotes or extra text.

Examples of good facts:
- The first oranges weren't orange - they were green
- A group of flamingos is called a "flamboyance"
- Honey never spoils - 3000-year-old honey is still edible
- Bananas are berries, but strawberries aren't
- There are more stars in space than grains of sand on Earth

Generate one completely unique and fascinating fact now:`;

export async function generateSnappleFact(customPrompt?: string, model?: string): Promise<string> {
  if (!isOpenAIEnabled || !openai) {
    throw new Error("AI features are not available. Please configure AI_INTEGRATIONS_OPENAI_API_KEY and AI_INTEGRATIONS_OPENAI_BASE_URL.");
  }

  const prompt = customPrompt || DEFAULT_PROMPT;

  // Use configured model from environment
  const config = getOpenAIConfig();
  const primaryModel = model || config.model;

  console.log("[OpenAI] Generating fact with model:", primaryModel);
  console.log("[OpenAI] Using prompt:", prompt.substring(0, 100) + "...");

  // Use configured model as primary, fallback to gpt-4o-mini for production compatibility
  const modelsToTry = [primaryModel, "gpt-4o-mini"].filter((m, i, arr) => arr.indexOf(m) === i);

  for (const currentModel of modelsToTry) {
    try {
      console.log("[OpenAI] Calling OpenAI API with model:", currentModel);
      const response = await openai.chat.completions.create({
        model: currentModel,
        messages: [{ role: "user", content: prompt }],
        max_completion_tokens: 200, // Newer models require max_completion_tokens instead of max_tokens
      });
      
      console.log("[OpenAI] Response received, choices:", response.choices?.length || 0);
      console.log("[OpenAI] Response content length:", response.choices[0]?.message?.content?.length || 0);
      
      const fact = response.choices[0]?.message?.content?.trim() || "";
      
      if (!fact) {
        console.log("[OpenAI] Empty fact from", currentModel, "- trying next model");
        continue; // Try next model
      }
      
      // Remove quotes if the AI wrapped the fact in them
      const cleanedFact = fact.replace(/^["']|["']$/g, "");
      console.log("[OpenAI] Final cleaned fact:", cleanedFact.substring(0, 100));
      
      return cleanedFact;
    } catch (error: any) {
      console.error("[OpenAI] Error with model", currentModel, ":", error.message || error);
      // Continue to next model instead of throwing
    }
  }

  // If all models failed, throw an error
  throw new Error("Failed to generate fact with any available model");
}
