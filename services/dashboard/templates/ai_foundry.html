{% extends "base.html" %}

{% block title %}Local AI Foundry - Ollama{% endblock %}

{% block content %}
<link rel="stylesheet" href="{{ url_for('static', filename='css/ai-foundry.css') }}">

<div class="ai-foundry-container">
    <div class="page-header">
        <h1><i class="bi bi-cpu"></i> Local AI Foundry</h1>
        <p class="subtitle">Ollama Model Management & Local ChatGPT Alternative</p>
    </div>
    
    <div class="models-section">
        <div class="section-header">
            <h2>AI Models</h2>
            <button class="btn btn-primary" onclick="showDownloadModal()">
                <i class="bi bi-download"></i> Download Model
            </button>
        </div>
        
        <div class="model-grid" id="modelGrid">
        </div>
    </div>
    
    <div class="chat-section">
        <h2>Local AI Chat</h2>
        <div class="model-selector">
            <label>Select Model:</label>
            <select id="modelSelect">
                <option value="llama2:7b">Llama 2 (7B)</option>
                <option value="mistral:latest">Mistral</option>
                <option value="codellama:latest">Code Llama</option>
            </select>
        </div>
        
        <div class="chat-box" id="chatBox">
            <div class="chat-message assistant">
                <strong>AI:</strong> Hello! I'm your local AI assistant running on Ollama. How can I help you?
            </div>
        </div>
        
        <div class="chat-input-area">
            <input type="text" id="chatInput" placeholder="Ask your local AI anything..." />
            <button onclick="sendMessage()" class="btn-send">
                <i class="bi bi-send"></i>
            </button>
        </div>
    </div>
</div>

<script src="{{ url_for('static', filename='js/ai-foundry.js') }}"></script>
{% endblock %}
