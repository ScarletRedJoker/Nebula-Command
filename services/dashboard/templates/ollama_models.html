{% extends "base.html" %}

{% block title %}AI Models - Nebula Command{% endblock %}

{% block content %}
<div class="row mb-4">
    <div class="col-12">
        <h2><i class="bi bi-cpu"></i> Local AI Models (Ollama)</h2>
        <p class="text-muted">Manage local AI models for privacy and unlimited free inference</p>
    </div>
</div>

<div class="row">
    <div class="col-md-8">
        <div class="card">
            <div class="card-header">
                <h5>Installed Models</h5>
            </div>
            <div class="card-body">
                <table class="table" id="modelsTable">
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Size</th>
                            <th>Modified</th>
                            <th>Actions</th>
                        </tr>
                    </thead>
                    <tbody id="modelsList">
                        <tr><td colspan="4" class="text-center">Loading...</td></tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>
    
    <div class="col-md-4">
        <div class="card">
            <div class="card-header">
                <h5>Pull New Model</h5>
            </div>
            <div class="card-body">
                <div class="mb-3">
                    <label class="form-label">Popular Models</label>
                    <select class="form-select" id="modelSelect">
                        <option value="llama3.2:latest">Llama 3.2 (3B)</option>
                        <option value="deepseek-r1:7b">DeepSeek R1 (7B)</option>
                        <option value="qwen2.5:7b">Qwen 2.5 (7B)</option>
                        <option value="codellama:latest">Code Llama</option>
                        <option value="mistral:latest">Mistral</option>
                        <option value="custom">Custom Model...</option>
                    </select>
                </div>
                <div class="mb-3" id="customModelInput" style="display:none;">
                    <input type="text" class="form-control" id="customModel" placeholder="model:tag">
                </div>
                <button class="btn btn-primary w-100" onclick="pullModel()">
                    <i class="bi bi-download"></i> Pull Model
                </button>
                <div id="pullProgress" class="mt-3" style="display:none;">
                    <div class="progress">
                        <div class="progress-bar" id="progressBar" style="width: 0%"></div>
                    </div>
                    <small id="progressText" class="text-muted">Downloading...</small>
                </div>
            </div>
        </div>
        
        <div class="card mt-3">
            <div class="card-header">
                <h5>About Ollama</h5>
            </div>
            <div class="card-body">
                <p class="small text-muted">
                    <strong>Privacy First:</strong> All AI inference runs locally on your hardware. No data leaves your network.<br><br>
                    <strong>Cost Effective:</strong> Free unlimited inference once models are downloaded.<br><br>
                    <strong>100+ Models:</strong> Access popular open-source models including Llama, Mistral, DeepSeek, Qwen, and more.
                </p>
            </div>
        </div>
    </div>
</div>

<script src="{{ url_for('static', filename='js/ollama_models.js') }}"></script>
{% endblock %}
