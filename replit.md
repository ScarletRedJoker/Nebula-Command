# Nebula Command

## Overview
Nebula Command is a creation engine for comprehensive homelab management, AI-powered content creation, Discord community integration, and multi-platform streaming. It provides a unified solution for digital creators and homelab enthusiasts, streamlining content generation, distribution, and community engagement. The platform is optimized for distributed deployment across cloud and local infrastructure, aiming to be a central hub for digital creation and homelab operations.

## User Preferences
- **Development Workflow:** Edit locally → Push to GitHub → Pull on servers
- **Database:** Shared PostgreSQL (Neon in dev, self-hosted in prod)
- **Secrets:** .env file (never commit)

## System Architecture

### Core Services
- **Dashboard (Next.js 14):** Web interface for homelab management, Docker controls, SSH metrics, deployment pipelines, code editor, visual website designer, and Jarvis AI assistant.
- **Discord Bot (Node.js/React):** Customizable bot for community management with per-server identity and granular feature toggles.
- **Stream Bot (Node.js/React/Vite):** Multi-platform content posting across Twitch, YouTube, and Kick.
- **Nebula Agent (Node.js/Express):** Runs on Windows VM for health monitoring, command execution, model management, and service control.

### Cross-Service Integration and Deployment
Services share a PostgreSQL database and Redis for caching, communicating via webhooks and APIs. The system employs a three-tier distributed deployment model:
- **Ubuntu Host (Home)**: Windows 11 VM with GPU passthrough for AI services.
- **Linode (Cloud)**: Hosts the Dashboard, Discord bot, and Stream bot.
- **Tailscale**: Provides secure mesh networking between all nodes.

### Platform Architecture
A three-layer design (Experience, Control Plane, Execution Plane) supports:
- A Marketplace API for Docker packages.
- An Agent Orchestrator API for managing AI agents.
- Service Discovery facilitated by `service-map.yml`.
- A Creative Studio for AI content generation.

### AI Node Management
The system monitors service health, GPU statistics, and package versions on AI nodes. It includes APIs for Speech, Job Scheduling, Training, and Embeddings/RAG, with unified model management via the dashboard and a Windows Model Agent.

### Creative Engine
The Creative Studio (`/creative-studio`) supports:
- Text-to-image, Image-to-image, and Inpainting.
- ControlNet, Upscaling, and Face Swap features.
- A database-backed pipeline ensures job persistence.

### Jarvis AI Orchestrator
This multi-agent AI system manages a job queue and subagents, supporting local-first resource selection, progress tracking, and integration with OpenCode for autonomous code development.

### Key Features
- **OOTB Setup Wizard** (`/setup`): Guided configuration for environment, secrets, database, AI, and platform connections.
- **Command Center** (`/command-center`): Unified control across all environments.
- **Deploy Center** (`/deploy`): Remote deployment and verification.
- **Services Manager** (`/services`): Container and service management.
- **Secrets Manager** (`/secrets-manager`): Secure credential management.
- **Jarvis AI** (`/jarvis`): AI chat assistant with tool calling.
- **Creative Studio** (`/creative`): AI image generation with ComfyUI/SD.
- **AI Models** (`/ai-models`): Model marketplace and management.
- **Workflows** (`/workflows`): Multi-step AI automation.
- **Agent Builder** (`/agents`): Custom AI agent configuration.
- **Pipelines** (`/pipelines`): Deployment automation.
- **Bot Editor** (`/bot-editor`): Discord bot customization.
- **Servers** (`/servers`): Server monitoring and control.
- **Windows VM** (`/windows`): GPU server management.
- **Domains** (`/domains`): DNS and SSL management.
- **Marketplace** (`/marketplace`): Docker package installation.

## External Dependencies
- **PostgreSQL:** Primary relational database.
- **Redis:** Caching and session management.
- **OpenAI API:** Cloud-based AI services (fallback).
- **Discord API (discord.js):** Discord Bot functionality.
- **Twitch/YouTube/Kick APIs:** Stream Bot integration.
- **Spotify API:** Music bot features.
- **Plex API:** "Now Playing" status.
- **Home Assistant API:** Homelab automation.
- **Cloudflare API:** DNS management.
- **Tailscale:** Secure network connectivity.
- **Caddy:** Reverse proxy.
- **Ollama:** Local LLM inference.
- **Stable Diffusion/ComfyUI:** Local image generation.

## Recent Changes

- **January 27, 2026**: ComfyUI Full Integration (Automation-Ready):
  - Database schema: `comfyui_workflows` and `comfyui_jobs` tables for workflow persistence and job tracking
  - Service Manager (`lib/ai/comfyui-manager.ts`): State detection (OFFLINE/STARTING/LOADING_MODELS/READY/DEGRADED), VRAM monitoring, readiness polling
  - Job Orchestrator (`lib/ai/comfyui-orchestrator.ts`): Workflow execution, exponential backoff retry (1s-16s), batch processing, job persistence
  - API Endpoints (`/api/ai/comfyui/*`): status, queue, workflows CRUD, execute, jobs, retry, batch
  - Dashboard UI (`/comfyui`): Status card, workflow management, job list, execution dialogs
  - Supports headless/remote operation via `COMFYUI_URL` environment variable
  - Future-ready for AI influencer pipelines, content factories, scheduled jobs

- **January 27, 2026**: AI Developer - Autonomous Code Modification System:
  - Database schema: `ai_dev_jobs`, `ai_dev_patches`, `ai_dev_approvals`, `ai_dev_runs`, `ai_dev_providers` tables
  - Provider Registry (`lib/ai/ai-dev/provider-registry.ts`): Multi-provider support (Ollama default, OpenAI, Anthropic)
  - Tool Interfaces (`lib/ai/ai-dev/tools.ts`): read_file, write_file, search_files, search_code, run_command, run_tests, git_diff
  - Repo Manager (`lib/ai/ai-dev/repo-manager.ts`): Diff generation, patch apply/rollback, git operations
  - Orchestrator (`lib/ai/ai-dev/orchestrator.ts`): Job lifecycle (pending→planning→executing→review→approved→applied), tool calling loop
  - API Endpoints (`/api/ai/dev/*`): jobs CRUD, job actions (execute/approve/reject/rollback), providers health, patches, approvals
  - Dashboard UI (`/ai-dev`): Job queue, create job dialog, diff viewer, approval workflow, provider health
  - Safeguards: Human approval gates, rollback support, path sandboxing, dangerous command blocking
  - No cloud lock-in: Works locally with Ollama, configurable via environment variables

- **January 27, 2026**: Production hardening - AI service configuration and logging:
  - Created centralized AI config system (lib/ai/config.ts) - environment-first configuration
  - Environment variables: WINDOWS_VM_TAILSCALE_IP, OLLAMA_URL, STABLE_DIFFUSION_URL, COMFYUI_URL
  - Implemented structured AI logging (lib/ai/logger.ts) for all AI operations with correlation IDs
  - Startup validation in instrumentation.ts for AI configuration
  - Dashboard error boundaries with context-aware guidance